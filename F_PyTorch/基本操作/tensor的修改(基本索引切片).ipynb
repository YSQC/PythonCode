{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# 完全类似numpy array的修改(基本索引切片)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302986751336\n",
      "1302962943304\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4, 5, 6, 7, 8])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "part = tor[2:5]\n",
    "print(id(part))\n",
    "part = torch.tensor([0, 0, 0, 0, 0]) # part整体重新进行赋值\n",
    "print(id(part)) # part内存地址改变\n",
    "tor # tor不变"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302986783064\n",
      "1302986783064\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([   1,    2, 9999, 9999, 9999, 9999, 9999,    8])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "part = tor[2:7]\n",
    "print(id(part))\n",
    "part[:] = 9999 # part部分[索引/切片]重新赋值\n",
    "print(id(part)) # part内存地址不变\n",
    "tor # tor发生改变(★★★★★修改tensor的方法1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 0, 0, 0, 6, 7, 8])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "tor[2:5] = torch.tensor([0, 0, 0]) # 直接对该[索引/切片]进行赋值;赋值时必须保证形式相同或可进行广播\n",
    "tor # tor发生改变(★★★★★修改tensor的方法2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([  1,   2,  99, 999, 999, 999,   7,   8])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "tor[2:][0:4] = torch.tensor([99, 999, 999, 999]) # 直接对该[索引/切片]的[索引/切片]进行赋值;赋值时必须保证形式相同或可进行广播\n",
    "tor # tor发生改变(★★★★★修改tensor的方法3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 实例"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0,  1,  2,  3,  4],\n         [ 5,  6,  7,  8,  9],\n         [10, 11, 12, 13, 14],\n         [15, 16, 17, 18, 19]],\n\n        [[20, 21, 22, 23, 24],\n         [25, 26, 27, 28, 29],\n         [30, 31, 32, 33, 34],\n         [35, 36, 37, 38, 39]],\n\n        [[40, 41, 42, 43, 44],\n         [45, 46, 47, 48, 49],\n         [50, 51, 52, 53, 54],\n         [55, 56, 57, 58, 59]]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor1 = torch.arange(60).reshape((3, 4, 5))\n",
    "tor1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[         0,          1,          2,          3,          4],\n         [         5,          6,          7,          8,          9],\n         [1111111111,         11,         12,         13,         14],\n         [        15,         16,         17,         18,         19]],\n\n        [[        20,         21,         22,         23,         24],\n         [        25,         26,         27,         28,         29],\n         [        30,         31,         32,         33,         34],\n         [        35,         36,         37,         38,         39]],\n\n        [[        40,         41,         42,         43,         44],\n         [        45,         46,         47,         48,         49],\n         [        50,         51,         52,         53,         54],\n         [        55,         56,         57,         58,         59]]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part = tor1[:, 2:, 0:3]\n",
    "part[0, 0, 0] = 1111111111 \n",
    "tor1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[  0,   1,   2,   3,   4],\n         [  5,   6,   7,   8,   9],\n         [  9,  99, 999,  13,  14],\n         [  9,  99, 999,  18,  19]],\n\n        [[ 20,  21,  22,  23,  24],\n         [ 25,  26,  27,  28,  29],\n         [  9,  99, 999,  33,  34],\n         [  9,  99, 999,  38,  39]],\n\n        [[ 40,  41,  42,  43,  44],\n         [ 45,  46,  47,  48,  49],\n         [  9,  99, 999,  53,  54],\n         [  9,  99, 999,  58,  59]]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 借助广播机制进行修改\n",
    "tor1[:, 2:, 0:3] = torch.tensor([9, 99, 999]) # [3, 2, 3] boradcasting [3, ] -->[3, 2, 3]\n",
    "tor1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[  0,   1,   2,   3,   4],\n         [  5,   6,   7,   8,   9],\n         [  8,  88, 888,  13,  14],\n         [  8,  88, 888,  18,  19]],\n\n        [[ 20,  21,  22,  23,  24],\n         [ 25,  26,  27,  28,  29],\n         [  8,  88, 888,  33,  34],\n         [  8,  88, 888,  38,  39]],\n\n        [[ 40,  41,  42,  43,  44],\n         [ 45,  46,  47,  48,  49],\n         [  8,  88, 888,  53,  54],\n         [  8,  88, 888,  58,  59]]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor1[:, 2:, 0:3] = torch.tensor([[8, 88, 888]]) # [3, 2, 3] boradcasting [1, 3] -->[3, 2, 3]\n",
    "tor1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[  0,   1,   2,   3,   4],\n         [  5,   6,   7,   8,   9],\n         [  6,  66, 666,  13,  14],\n         [  7,  77, 777,  18,  19]],\n\n        [[ 20,  21,  22,  23,  24],\n         [ 25,  26,  27,  28,  29],\n         [  6,  66, 666,  33,  34],\n         [  7,  77, 777,  38,  39]],\n\n        [[ 40,  41,  42,  43,  44],\n         [ 45,  46,  47,  48,  49],\n         [  6,  66, 666,  53,  54],\n         [  7,  77, 777,  58,  59]]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor1[:, 2:, 0:3] = torch.tensor([[6, 66, 666],\n",
    "                             [7, 77, 777]]) # [3, 2, 3] boradcasting [2, 3] -->[3, 2, 3]\n",
    "tor1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}